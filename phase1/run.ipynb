{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "####### TRAINING CODE CELL ######\n",
    "#################################\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, PreTrainedModel, AutoConfig\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "# PREP ELEMENT\n",
    "def prep_element(x):\n",
    "    return torch.permute(torch.stack(x), dims=[1,0]).to(device)\n",
    "\n",
    "# GET ACC\n",
    "def get_acc(preds, labels, threshold=0.5):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_preds = sig(preds)\n",
    "\n",
    "    new_preds = new_preds.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    binary_preds = (new_preds >= threshold).astype(np.float32)\n",
    "\n",
    "    weak_preds = (binary_preds == labels).mean(axis=1).astype(np.float32)\n",
    "    weak_accuracy = weak_preds.sum() / len(labels)\n",
    "\n",
    "    return weak_accuracy.item()\n",
    "\n",
    "\n",
    "# FIX RANDOM SEED\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# PROCESS CODE\n",
    "def process(example):\n",
    "    q = questions[example['Q_number'] - 1]\n",
    "    a = example['Answer']\n",
    "    sex, age = example['Gender'], example['Age']\n",
    "    sex = '남자' if sex == 0 else '여자'\n",
    "    inp = f'{sex}, {age}세' + ' 질문: ' + q + ' 답변: ' + a   \n",
    "    result = tokenizer(inp, max_length=144, padding='max_length', truncation=True, return_tensors='pt') # 96~97%.\n",
    "    \n",
    "    for k in result:\n",
    "        example[k] = result[k].squeeze(0)\n",
    "    \n",
    "    example['labels'] = torch.Tensor([0 if x in \"ISTJ\" else 1 for x in example['MBTI']])\n",
    "    return example\n",
    "\n",
    "\n",
    "### MODEL CODE START ###\n",
    "class ClfModel(PreTrainedModel):\n",
    "    def __init__(self, config, out_size=1024):\n",
    "        super(ClfModel, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.model = AutoModel.from_pretrained(config_._name_or_path)\n",
    "        \n",
    "        self.out = out_size\n",
    "        \n",
    "        self.nn_1 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )\n",
    "        self.nn_2 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )        \n",
    "        \n",
    "        self.nn_3 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )        \n",
    "        \n",
    "        self.nn_4 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, **kwargs):\n",
    "        out = self.model(input_ids=input_ids, attention_mask=attention_mask)['last_hidden_state'][:, 0, :] # select first token.\n",
    "        \n",
    "        out1 = self.nn_1(out)\n",
    "        out2 = self.nn_2(out)\n",
    "        out3 = self.nn_3(out)\n",
    "        out4 = self.nn_4(out)\n",
    "\n",
    "        return out1, out2, out3, out4\n",
    "\n",
    "### END OF MODEL CODE ###\n",
    "\n",
    "rseed = 123\n",
    "set_seed(rseed)\n",
    "\n",
    "# Best Training setting would be to give New Data's 49~60 + Conventional K-Fold.\n",
    "df = pd.read_csv(\"/workspace/final_QIA/phase1/train.csv\") # 0 ~ 240까지는 phase 1.\n",
    "\n",
    "# shuffle quesiton numbers\n",
    "q_numbers = list(range(1, 49))\n",
    "q_numbers_aux = list(range(49, 61))\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "SPLIT_NUM = 5\n",
    "\n",
    "kf = KFold(n_splits=SPLIT_NUM, shuffle=True, random_state=rseed)\n",
    "\n",
    "for CURR_IDX in range(SPLIT_NUM):\n",
    "    kf_ = [x for x in kf.split(q_numbers)]\n",
    "\n",
    "    train = [1+x for x in kf_[CURR_IDX][0]] # 38\n",
    "    val = [1+x for x in kf_[CURR_IDX][1]] # 10\n",
    "\n",
    "    # train_df =  df[df.Q_number.isin(q_numbers_aux)]], axis=0) # 38 * 360 + 12 * 120 = 15120\n",
    "    # val_df = df[df.Q_number.isin(val)] # 10 * 360 = 3600\n",
    "\n",
    "    # train_df = df[df.Q_number.isin(train)]\n",
    "    # val_df = pd.concat([df[df.Q_number.isin(q_numbers_aux)], df[df.Q_number.isin(val)]], axis=0)\n",
    "    \n",
    "    train_df = df[df.Q_number.isin(train)]\n",
    "    val_df = df[df.Q_number.isin(val)]\n",
    "\n",
    "\n",
    "    train_dset = Dataset.from_pandas(train_df)\n",
    "    val_dset = Dataset.from_pandas(val_df)\n",
    "    mbti = list(df.MBTI.unique())\n",
    "\n",
    "    model_name = \"klue/roberta-large\"\n",
    "    model_path = f\"/workspace/final_QIA/models/{model_name}\"\n",
    "\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    questions = pd.read_excel(\"/workspace/final_QIA/phase1/Question.xlsx\")\n",
    "    questions = questions.Question.tolist()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    config_ = AutoConfig.from_pretrained(model_name)\n",
    "    model = ClfModel(config_, out_size=1024)\n",
    "\n",
    "    columns_to_remove = ['MBTI', 'Answer', 'Short_Answer', '__index_level_0__']\n",
    "    train_dset = train_dset.map(lambda x: process(x), remove_columns= columns_to_remove)\n",
    "    val_dset = val_dset.map(lambda x: process(x), remove_columns= columns_to_remove)\n",
    "\n",
    "    train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dset, batch_size=32, shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()  \n",
    "    scheduler = LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "    \n",
    "    best_acc = 0\n",
    "\n",
    "    EPOCHS = 10\n",
    "\n",
    "    print(\"Initiate Training ...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "    \n",
    "        # Basic initital settings.\n",
    "        train_loss, test_loss, train_wacc, train_sacc, test_wacc, test_sacc = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        scheduler.step() \n",
    "        \n",
    "        ### TRAINING ###\n",
    "        model.train()\n",
    "        \n",
    "        with tqdm(train_loader, unit=\"batch\") as t_epoch:\n",
    "            for batch in t_epoch:\n",
    "                t_epoch.set_description(f\"Training at Epoch {epoch+1}\")\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = model(\n",
    "                    input_ids= prep_element(batch[\"input_ids\"]),\n",
    "                    attention_mask = prep_element(batch[\"attention_mask\"])\n",
    "                )\n",
    "\n",
    "                loss = criterion(torch.permute(torch.stack(output).squeeze(-1), dims=[1,0]), prep_element(batch[\"labels\"]).squeeze(-1))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_wacc += get_acc(torch.permute(torch.stack(output).squeeze(-1), dims=[1,0]), prep_element(batch[\"labels\"]).squeeze(-1), 0.5)\n",
    "\n",
    "                # t_epoch.set_postfix(loss=loss.item(), accuracy= 100*float((pred == label).to(torch.float).mean()))\n",
    "        \n",
    "        tr_len = len(train_loader)\n",
    "\n",
    "        # Trivial Error\n",
    "        avg_train_loss = train_loss / tr_len\n",
    "        avg_train_wacc = train_wacc / tr_len\n",
    "\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(\"Train Loss: {:.4f}\".format(avg_train_loss))\n",
    "        print(\"Train Weak Acc: {:.4f}\".format(avg_train_wacc))\n",
    "\n",
    "        ### VALIDATION ###\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, unit=\"batch\") as v_epoch:\n",
    "                for batch in v_epoch:\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        output = model(\n",
    "                            input_ids= prep_element(batch[\"input_ids\"]),\n",
    "                            attention_mask = prep_element(batch[\"attention_mask\"])\n",
    "                        )\n",
    "\n",
    "\n",
    "                    loss = criterion(torch.permute(torch.stack(output).squeeze(-1), dims=[1,0]), prep_element(batch[\"labels\"]).squeeze(-1))\n",
    "\n",
    "                    test_loss += loss.item()\n",
    "                    test_wacc +=  get_acc(torch.permute(torch.stack(output).squeeze(-1), dims=[1,0]), prep_element(batch[\"labels\"]).squeeze(-1), 0.5)\n",
    "\n",
    "                    # v_epoch.set_postfix(loss=loss.item(), accuracy= 100*float((pred == label).to(torch.float).mean()))\n",
    "\n",
    "            te_len = len(val_loader)\n",
    "\n",
    "            # Trivial Error\n",
    "            avg_test_loss = test_loss / te_len\n",
    "            avg_test_wacc = test_wacc / te_len\n",
    "\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(\"Test Loss: {:.4f}\".format(avg_test_loss))\n",
    "        print(\"Test Weak Acc: {:.4f}\".format(avg_test_wacc))\n",
    "\n",
    "        ## Saving\n",
    "        ckpt = {'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_acc': avg_train_wacc,\n",
    "                'test_acc': avg_test_wacc,\n",
    "                }\n",
    "\n",
    "        if avg_test_wacc > best_acc:\n",
    "            best_acc = avg_test_wacc\n",
    "            torch.save(ckpt, f\"{model_path}/klue_roberta_base_{CURR_IDX}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### CHECK VALIDATION ACCURACY ###\n",
    "#################################\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "s = sorted(glob.glob(\"/workspace/final_QIA/models/*/*/*\"))\n",
    "\n",
    "for x in s:\n",
    "    e = torch.load(x, map_location='cpu')\n",
    "    print(x.split(\"/\")[-1], e['train_acc'], e['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "####### TESTING CODE CELL ######\n",
    "#################################\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import Dataset \n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, PreTrainedModel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import statistics\n",
    "\n",
    "model_name = \"klue/roberta-large\"\n",
    "fname = \"0521_final_test_file.csv\"\n",
    "\n",
    "# INFERENCE\n",
    "\n",
    "# df_test = pd.merge(df_test1, questions, left_on='Q_number', right_on='index', how='inner')\n",
    "\n",
    "# PREP ELEMENT\n",
    "def prep_element(x):\n",
    "    return torch.permute(torch.stack(x), dims=[1,0]).to(device)\n",
    "\n",
    "\n",
    "def test_process(example, tokenizer):\n",
    "    q = questions[example['Q_number'] - 1]\n",
    "    a = example['Answer']\n",
    "\n",
    "    sex, age = example['Gender'], example['Age']\n",
    "    sex = '남자' if sex == 0 else '여자'\n",
    "    inp = f'{sex}, {age}세 질문: ' + q + \" 답변: \" + a\n",
    "    result = tokenizer(inp, max_length=144, padding='max_length', truncation=True, return_tensors='pt') # 96~97%.\n",
    "\n",
    "    for k in result:\n",
    "        example[k] = result[k].squeeze(0)\n",
    "\n",
    "    return example    \n",
    "\n",
    "\n",
    "### MODEL CODE START ###\n",
    "class ClfModel(PreTrainedModel):\n",
    "    def __init__(self, config, out_size=1024):\n",
    "        super(ClfModel, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.model = AutoModel.from_pretrained(config_._name_or_path)\n",
    "        \n",
    "        self.out = out_size\n",
    "        \n",
    "        self.nn_1 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )\n",
    "        self.nn_2 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )        \n",
    "        \n",
    "        self.nn_3 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )        \n",
    "        \n",
    "        self.nn_4 = nn.Sequential(\n",
    "         nn.Dropout(p=0.1),\n",
    "         nn.Linear(self.out, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, **kwargs):\n",
    "        out = self.model(input_ids=input_ids, attention_mask=attention_mask)['last_hidden_state'][:, 0, :] # select first token.\n",
    "        \n",
    "        out1 = self.nn_1(out)\n",
    "        out2 = self.nn_2(out)\n",
    "        out3 = self.nn_3(out)\n",
    "        out4 = self.nn_4(out)\n",
    "\n",
    "        return out1, out2, out3, out4\n",
    "\n",
    "### END OF MODEL CODE ###\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"/workspace/final_QIA/phase1/test.csv\")\n",
    "questions = pd.read_excel(\"/workspace/final_QIA/phase1/Question.xlsx\")\n",
    "questions = questions.Question.tolist()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "test_set = Dataset.from_pandas(df_test)\n",
    "test_set = test_set.map(lambda x: test_process(x, tokenizer))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "ensemble_final_preds = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "model_name = \"klue/roberta-large\"\n",
    "model_path = f\"/workspace/final_QIA/models/{model_name}\"\n",
    "\n",
    "questions = pd.read_excel(\"/workspace/final_QIA/phase1/Question.xlsx\")\n",
    "questions = questions.Question.tolist()\n",
    "\n",
    "for test_model_path in sorted(glob.glob(\"/workspace/final_QIA/models/*/*/*\")):\n",
    "\n",
    "    results = []\n",
    "    # test_model_path = f\"/workspace/QIA/outputs/klue/roberta-large/klue_roberta_large_{IDX_NUM_TEST}.pth\"\n",
    "    print(\"Loading\", test_model_path)\n",
    "\n",
    "    # Load the model and specify the task\n",
    "    if 'roberta-base' in test_model_path:\n",
    "        continue\n",
    "        \n",
    "    elif 'roberta-large' in test_model_path:\n",
    "        config_ = AutoConfig.from_pretrained('klue/roberta-large')\n",
    "        model = ClfModel(config_, out_size=1024).to(device)\n",
    "\n",
    "    elif 'kobigbird-bert-base' in test_model_path:\n",
    "        config_ = AutoConfig.from_pretrained('monologg/kobigbird-bert-base')\n",
    "        model = ClfModel(config_, out_size=768).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(test_model_path)['model'])\n",
    "    model.to(device)\n",
    "    \n",
    "    # Get all the results by running the model on the dataset\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(\n",
    "                input_ids= prep_element(batch[\"input_ids\"]),\n",
    "                attention_mask = prep_element(batch[\"attention_mask\"])\n",
    "            )\n",
    "\n",
    "            results.append(torch.stack(output).squeeze().permute(dims=[1,0]).detach().cpu())\n",
    "\n",
    "    final_results = torch.stack(results).reshape(-1, 4)\n",
    "    final_results = sigmoid(final_results)\n",
    "    ensemble_final_preds.append(final_results)\n",
    "\n",
    "\n",
    "# define the column names\n",
    "fieldnames = ['idx', 'I/E', 'S/N', 'T/F', 'J/P']\n",
    "\n",
    "def avg2(li):\n",
    "    median = statistics.median(li)\n",
    "    stdev = statistics.stdev(li)\n",
    "    lower_bound = median - 2.5 * stdev\n",
    "    upper_bound = median + 2.5 * stdev\n",
    "    non_outliers = [x for x in li if lower_bound <= x <= upper_bound]\n",
    "    return sum(non_outliers) / len(non_outliers)\n",
    "\n",
    "def avg(li):\n",
    "    avg_val = sum(li) / len(li)\n",
    "    return avg_val\n",
    "\n",
    "\n",
    "# open the CSV file for writing\n",
    "with open(f\"/workspace/final_QIA_{fname}\", 'w', newline='') as csvfile:\n",
    "    # create a writer object\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    for idx in tqdm(range(len(ensemble_final_preds[0]))):\n",
    "        \n",
    "        # Majority voting\n",
    "        ie = avg([x[idx][0].item() for x in ensemble_final_preds])\n",
    "        sn = avg([x[idx][1].item() for x in ensemble_final_preds])\n",
    "        tf = avg([x[idx][2].item() for x in ensemble_final_preds])\n",
    "        jp = avg([x[idx][3].item() for x in ensemble_final_preds])\n",
    "\n",
    "        writer.writerow({\n",
    "            'idx': idx + 1,\n",
    "            'I/E': ie,\n",
    "            'S/N': sn,\n",
    "            'T/F': tf,\n",
    "            'J/P': jp\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
